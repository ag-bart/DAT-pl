{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb8654ed-920f-467a-b8e8-6454e6cf6a66",
   "metadata": {},
   "source": [
    "# **Run the cells below to prepare the data (REQUIRED)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847db2e5-2179-41e0-bcd9-a1ebeea8dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import time\n",
    "import dat\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cedd46e8-c469-40b6-b144-151fd3619357",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dat.Model(\"glove_100_3_polish.txt\", \"words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8782947b-9ed2-447c-8e30-65f726dabf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc58f6975304b93a61c61da70771aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.xlsx', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uploader = widgets.FileUpload(\n",
    "    accept='.xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=False  # True to accept multiple files upload else False\n",
    ")\n",
    "\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28fd41d7-727a-47a8-beab-3525be15b5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload successful\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    input_file = list(uploader.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    df_upload = pd.read_excel(content, header=None)\n",
    "    df_upload = df_upload.fillna(value=\" \")\n",
    "    data = df_upload.values.tolist()\n",
    "    print(\"upload successful\")\n",
    "    \n",
    "except IndexError:\n",
    "    print(\"upload a file first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea903b90-3492-4f66-a365-5eeae17261e9",
   "metadata": {},
   "source": [
    "**Run cell below to obtain the DAT score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40118db2-08f3-4055-a0ae-7d4a07c0fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.87\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    x = model.dat(i)\n",
    "    if x != None:\n",
    "        print(x.round(2))\n",
    "    else:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a6e54-37c9-4382-ab19-880605dbfad3",
   "metadata": {},
   "source": [
    "**Run cell below to obtain words not found in model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b5b2cc4-d62b-4cb8-b3e6-5d3b531712cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chusteczki\n",
      "ksiażka\n",
      "ochraniacz-na-zęby\n",
      "zamek-drzewo-kość-lakier-lilijka-znak-poduszka-piernik-kamień-kosz\n",
      "rośliny\n",
      "zasłony, leki\n",
      "chmury, książki, wiśnie\n",
      "netflix\n",
      "woda-ogień, sąsiad-przyjaciel, książka-podręcznik\n",
      "buty\n",
      "szkicowanie\n",
      "kalosze, widom, gwiazda-śmierci\n",
      "pieniądze\n",
      "pieniądze\n",
      "problemy, rozwiązania\n",
      "myśli\n",
      "perfum\n",
      "chusteczki\n",
      "słup-graniczny\n",
      "psy, rośliny, flamastry\n",
      "narkotyki\n",
      "marzenia, najlepszy\n",
      "pierogi\n",
      "szuflady\n",
      "oczy\n",
      "pieniądze, przyjażń\n",
      "instagram, gry, netflix\n",
      "zęby\n",
      "miksolog\n",
      "facebook\n",
      "rękawice\n",
      "leki\n",
      "ostrzeszów\n",
      "przemyślenia\n",
      "obrazy, zwierciadła\n",
      "odtrącenie\n",
      "paznokiec\n",
      "swiatlo\n",
      "tory\n",
      "mamdarynka\n",
      "łózko\n"
     ]
    }
   ],
   "source": [
    "inv_words_list = []\n",
    "\n",
    "for i in data:\n",
    "    x = model.invalid_words(i)\n",
    "    if len(x) < 1:\n",
    "        continue\n",
    "    print(', '.join(x))\n",
    "    inv_words_list.append(x)\n",
    "    \n",
    "if len(inv_words_list) < 1:\n",
    "    print(\"no invalid words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f087b-4361-42ee-b2d7-c9f7f4989572",
   "metadata": {},
   "source": [
    "**Run cell below to obtain a html file with word distances matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fa8df10-aed7-4d13-9ffe-052cf7182394",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = time.strftime(\"%Y-%b-%d__%H_%M_%S\",time.localtime())\n",
    "\n",
    "word_pairs = []\n",
    "dat_list = []\n",
    "\n",
    "for i in data:\n",
    "    x = model.dat(i, 1)\n",
    "    y = model.dat(i)\n",
    "    if x != None:\n",
    "        word_pairs.append(x)\n",
    "    if y != None:\n",
    "        dat_list.append(y.round(2))\n",
    "\n",
    "f=open(\"dat_matrix\"+date+\".html\",\"w\")\n",
    "f.write('<meta charset=\"UTF-8\">')\n",
    "\n",
    "score = 0\n",
    "for pairs in word_pairs:\n",
    "    tags = []\n",
    "    for t1, t2, _ in pairs:\n",
    "        tags += [t1, t2]\n",
    "        \n",
    "    tags = index = columns = sorted(list(set(tags)))\n",
    "    tags = dict((t, i) for i, t in enumerate(tags))\n",
    "    correlation = np.identity(len(tags))\n",
    "    \n",
    "    for t1, t2, corr in pairs:\n",
    "        correlation[tags[t1]][tags[t2]] = corr\n",
    "        correlation[tags[t2]][tags[t1]] = corr\n",
    "        \n",
    "    df = pd.DataFrame(correlation, index=index, columns=columns)\n",
    "    \n",
    "    mask = np.zeros_like(df, dtype=bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    df[mask] = np.nan\n",
    "    df_style = (df\n",
    "    .style\n",
    "    .background_gradient(cmap='RdYlGn', axis=None, vmin=0, vmax=1)\n",
    "    .highlight_null(null_color='#f1f1f1')\n",
    "    .set_precision(2))\n",
    "    \n",
    "    f.write(df_style.render())\n",
    "    f.write(\"DAT: \" + str(dat_list[score]))\n",
    "    \n",
    "    score = score + 1\n",
    "    \n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
